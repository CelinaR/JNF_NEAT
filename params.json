{
  "name": "Jnf neat",
  "tagline": "Actually usable implementation of NEAT",
  "body": "# JNF_NEAT\r\n\r\nMy implementation of Kenneth Stanley and Risto Miikkulainen's NEAT (NeuroEvolution\r\nof Augmenting Topologies, http://nn.cs.utexas.edu/downloads/papers/stanley.ec02.pdf).\r\n\r\nIt focuses (in contrast to other implementations) on\r\n\r\n- Speed - through modern and efficient C++14\r\n- Clean Code - through constant ongoing refactoring and a deep care for aesthetics\r\n- Usability - through being able to be used without much knowledge of Neural Networks\r\n- Platform Independency - written on three different operating systems (Windows, Ubuntu, MacOS X) and two different IDEs (Visual Studio 2015, CLion), it is safe to say, that it will work on multiple platforms, flawlessly.\r\n\r\n##Foreword\r\n\r\n###Motivation\r\nOne of the problems of machine learning is its steep learning curve. If you want to let your code learn,\r\nyou've got few choices: Use expensive proprietary modules or use libraries that are aimed at people with experience in AI.\r\nIf you want to learn how machine learning works, you've got to read scientific papers with tons of buzzwords.\r\nThe provided code is often made by people who are brilliant at researching, but have only got poor programming skills.\r\n\r\nWe think this is a shame. A programmer shouldn't have to learn about the internals of a class.\r\nHe should be able to use it intuitively, in a matter that it relieves him from work, not set him up for more.\r\nThat's the age old principle of encapsulation!\r\n\r\nAnother problem we've encountered, was platform dependency. Despite being conceived as a platform independent language,\r\nwe encountered various implementations of NEAT, that managed to break this. Examples included code with for loops looking like this:\r\n```\r\nfor( i = 0; i < 10; i++ ){  \r\n    ...\r\n}\r\n```\r\nNotice the `i` not having been declared? Some compilers permit this. Another, more subtle one was the `abstract` keyword\r\nof Microsoft Visual Studio. It's actually not part of the language. The official way is to write an (admittedly more arbitrary) `= 0`\r\nat the end of a function.\r\n\r\n###What is NEAT?\r\n\r\nN/A\r\n\r\n##Usage  \r\nYou first have to provide an implementation of the `IBody` interface. You need to provide a copy constructor as well as following methods:   \r\n- Update()  \r\n- GetFitness()  \r\n- Reset  \r\n- ProvideNetworkWithInputs()  \r\n\r\nThey are all explained in detail below.  \r\n<details>\r\n<summary>Example</summary>\r\nN/A\r\n</details>\r\n\r\nYou need to instantiate a `NeuralNetworkTrainer::TrainingParameters` object. You **have** to set its `numberOfInputs`, `numberOfOutputs`, `updatesPerGeneration` members.  \r\nIf you know what you're doing, you can change the members in the `advanced` structure to tweak the learning process.  \r\n\r\n<details>\r\n<summary>Example</summary>\r\n```\r\nTrainingParameters params;\r\nparams.numberOfInputs = 2;\r\nparams.numberOfOutputs = 1;\r\nparams.updatesPerGeneration = 4;\r\n```\r\n</details>\r\n\r\n\r\nThen, you'll want to create a `NeuralNetworkTrainer` instance with our `TrainingParameters`.\r\n<details>\r\n<summary>Example</summary>\r\nN/A\r\n</details>\r\n\r\n## Explanation of IBody\r\n### Update()\r\nThis method gets called automatically multiple times during training.\r\n\r\nThe actions of your object should take place here. This almost always boils down to **executing the command the Neural Network decides to use**. This information is delivered to you by the parameter `const std::vector<float>& networkOutputs`.\r\n<details>\r\n<summary>Example</summary>\r\nSay you want to train an artificial player for Super Mario World. This method should then take care of actually pressing the buttons your network want you to. In this specific case, it should also update the whole game for a frame, so enemies and items can react to Mario. A possible interpretention of the `networkOutputs` would be to say that every float in the vector is a button and should be pressed if it's value is above `0.5`.\r\n</details>\r\n### GetFitness()\r\nThis method tells the trainer how good this specific instance is compared to others.\r\nIt gets called automatically when the `INetworkTrainer` object dies\r\nIt's used to generate this objects offspring, with a fitness score of zero or lower meaning that this individuals genes are not going to get passed on\r\n\r\nNote that in very analog programs such as real world simulations, true perfection should be unreachable\r\n<details>\r\n<summary>Example</summary>\r\nA simulated chess player could have a fitness method implemented like this:\r\n```sh\r\nint ChessSim::GetFitness() const {\r\n  unsigned int fitness = 0;\r\n  for (const auto & piece : enemyKilledPieces) {\r\n    fitness += piece.GetImportance();\r\n  }\r\n  for (const auto & piece : ownKilledPieces) {\r\n    fitness -= piece.GetImportance();\r\n  }\r\n  return fitness;\r\n}\r\n```  \r\nor, if you store a member `fitness` that you change in the Update() function.  \r\n```sh\r\nint ChessSim::GetFitness() const {\r\n    return fitness\r\n}\r\n```\r\n</details>\r\n### Reset()\r\nThis method gets called after your training object has finished its lifecicle and starts to train again with different neural configurations. It should reset the training object to the state it had before training.  \r\n\r\nIf you decide to use a member to store the `fitness`, it should be set to zero in here.\r\n\r\n<details>\r\n<summary>Example</summary>\r\n If you are programming a Super Mario World player, the code to restart the level should be in here\r\n</details>\r\n### ProvideNetworkWithInputs()\r\nThis method describes what your network \"sees\". It get's called automatically whenever your network needs updated real world knowledge.\r\nRemember that it works with a vector of floats, so most of the time you'll want to translate your\r\ninputs by dividing them by their maximally possible values.\r\n<details>\r\n<summary>Example</summary>\r\nLet's assume you want to create a handwriting reader.\r\nYour input would be a 20 pixels wide and 20 pixels high image of a hand drawn letter.\r\nIn order to feed the neural network with this information,\r\nwe'll create a vector with 20 * 20 = 400 inputs, each one having a value between 0.0 and 1.0 that represents this pixels blackness.\r\nWe can do this in a variety of ways. One of them would be to add the RGB values of the pixel up and divide them by\r\nthe maximum possible, 255+255+255 = 765. By this method, a bright red pixel(255,0,0) would be represented in our 400 element vector by\r\nthe number 255 / 765 = 0.3333.\r\n </details>\r\n \r\n## FAQ\r\n\r\nN/A\r\n\r\n## Design decisions\r\n\r\nN/A\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}